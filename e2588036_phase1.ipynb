{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "MOsHUjgdIrIW",
    "ExecuteTime": {
     "end_time": "2024-11-30T12:42:15.336584Z",
     "start_time": "2024-11-30T12:42:12.811012Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/homebrew/lib/python3.10/site-packages (2.2.3)\r\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2.0.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/ceskici/Library/Python/3.10/lib/python/site-packages (from pandas) (2024.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/lib/python3.10/site-packages (from pandas) (2024.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.10 -m pip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.10/site-packages (3.9.1)\r\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.10/site-packages (from nltk) (8.1.7)\r\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.10/site-packages (from nltk) (1.4.2)\r\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/homebrew/lib/python3.10/site-packages (from nltk) (2024.11.6)\r\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.10/site-packages (from nltk) (4.67.1)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.10 -m pip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: spacy in /opt/homebrew/lib/python3.10/site-packages (3.8.2)\r\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (3.0.12)\r\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (1.0.5)\r\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (1.0.11)\r\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (3.0.9)\r\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (8.3.2)\r\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (1.1.3)\r\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.4.8)\r\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.0.10)\r\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (0.4.1)\r\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (0.14.0)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (4.67.1)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.32.3)\r\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.10.2)\r\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (3.1.4)\r\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/lib/python3.10/site-packages (from spacy) (74.1.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (24.2)\r\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (3.5.0)\r\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/homebrew/lib/python3.10/site-packages (from spacy) (2.0.2)\r\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/homebrew/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\r\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/homebrew/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /opt/homebrew/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.27.1)\r\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/homebrew/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\r\n",
      "Requirement already satisfied: blis<1.1.0,>=1.0.0 in /opt/homebrew/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (1.0.1)\r\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/homebrew/lib/python3.10/site-packages (from thinc<8.4.0,>=8.3.0->spacy) (0.1.5)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\r\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/homebrew/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\r\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.9.4)\r\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/homebrew/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.20.0)\r\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/homebrew/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.5)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from jinja2->spacy) (3.0.2)\r\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in /opt/homebrew/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\r\n",
      "Requirement already satisfied: wrapt in /opt/homebrew/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.10 -m pip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.10/site-packages (1.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (2.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.10 -m pip install --upgrade pip\u001B[0m\r\n",
      "Requirement already satisfied: sklearn-crfsuite in /opt/homebrew/lib/python3.10/site-packages (0.5.0)\r\n",
      "Requirement already satisfied: python-crfsuite>=0.9.7 in /opt/homebrew/lib/python3.10/site-packages (from sklearn-crfsuite) (0.9.11)\r\n",
      "Requirement already satisfied: scikit-learn>=0.24.0 in /opt/homebrew/lib/python3.10/site-packages (from sklearn-crfsuite) (1.5.2)\r\n",
      "Requirement already satisfied: tabulate>=0.4.2 in /opt/homebrew/lib/python3.10/site-packages (from sklearn-crfsuite) (0.9.0)\r\n",
      "Requirement already satisfied: tqdm>=2.0 in /opt/homebrew/lib/python3.10/site-packages (from sklearn-crfsuite) (4.67.1)\r\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (2.0.2)\r\n",
      "Requirement already satisfied: scipy>=1.6.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.14.1)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/homebrew/lib/python3.10/site-packages (from scikit-learn>=0.24.0->sklearn-crfsuite) (3.5.0)\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.2\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpython3.10 -m pip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "source": [
    "# write the list of necessary packages here:\n",
    "!pip install pandas\n",
    "!pip install nltk\n",
    "!pip install spacy\n",
    "!pip install scikit-learn\n",
    "!pip install sklearn-crfsuite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEJBSTyZIrIb"
   },
   "source": [
    "## Training a model on Named Entity Recognition task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7AGryS1Ugtua"
   },
   "source": [
    "Token classification refers to the task of classifying individual tokens in a sentence. One of the most common token\n",
    "classification tasks is Named Entity Recognition (NER). NER attempts to find a label for each entity in a sentence,\n",
    "such as a person, location, or organization. In this assignment, you will learn how to train a model on the [CoNLL 2023 NER Dataset](https://www.clips.uantwerpen.be/conll2003/ner/) dataset to detect new entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whPRbBNbIrIl"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IreSlFmlIrIm",
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# import your packages here:\n",
    "import pandas as pd\n",
    "from sklearn_crfsuite import CRF, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T07:24:54.351213Z",
     "start_time": "2024-12-01T07:24:54.266417Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(204566, 4), (51577, 4), (46665, 4)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"ner_data/train.txt\", header=0, sep=\" \")\n",
    "val_df = pd.read_csv(\"ner_data/val.txt\", header=0, sep=\" \")\n",
    "test_df = pd.read_csv(\"ner_data/test.txt\", header=0, sep=\" \")\n",
    "\n",
    "print(f\"{train_df.shape}, {val_df.shape}, {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CoNLL-2003 shared task data files contain four columns separated by a single space. Each word has been put on a separate line and there is an empty line after each sentence. The first item on each line is a word, the second a part-of-speech (POS) tag, the third a syntactic chunk tag and the fourth the named entity tag. The chunk tags and the named entity tags have the format I-TYPE which means that the word is inside a phrase of type TYPE. Only if two phrases of the same type immediately follow each other, the first word of the second phrase will have tag B-TYPE to show that it starts a new phrase. A word with tag O is not part of a phrase. Here is an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T07:24:56.902359Z",
     "start_time": "2024-12-01T07:24:56.897137Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "  -DOCSTART-  -X- -X-.1       O\n0         EU  NNP  B-NP   B-ORG\n1    rejects  VBZ  B-VP       O\n2     German   JJ  B-NP  B-MISC\n3       call   NN  I-NP       O\n4         to   TO  B-VP       O",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>-DOCSTART-</th>\n      <th>-X-</th>\n      <th>-X-.1</th>\n      <th>O</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>EU</td>\n      <td>NNP</td>\n      <td>B-NP</td>\n      <td>B-ORG</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>rejects</td>\n      <td>VBZ</td>\n      <td>B-VP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>German</td>\n      <td>JJ</td>\n      <td>B-NP</td>\n      <td>B-MISC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>call</td>\n      <td>NN</td>\n      <td>I-NP</td>\n      <td>O</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>to</td>\n      <td>TO</td>\n      <td>B-VP</td>\n      <td>O</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T07:24:57.687222Z",
     "start_time": "2024-12-01T07:24:57.676500Z"
    }
   },
   "outputs": [],
   "source": [
    "label_list = ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']\n",
    "\n",
    "labels_vocab = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
    "labels_vocab_reverse = {v:k for k,v in labels_vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction\n",
    " \n",
    "You need to extract features for each token. The features can be:\n",
    "• Basic features: Token itself, token lowercase, prefix/suffix of the token.\n",
    "• Context features: Neighboring tokens (previous/next token).\n",
    "• Linguistic features: Part-of-speech (POS) tags or word shapes (capitalization, digits,\n",
    "etc.).\n",
    "Note that you are expected to briefly mention which features you employ for training your\n",
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "outputs": [],
   "source": [
    "def prepare_sentences(df):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    for _, row in df.iterrows():\n",
    "        if pd.isna(row.iloc[0]): \n",
    "            if sentence:\n",
    "                sentences.append(sentence)\n",
    "                sentence = []\n",
    "        else:\n",
    "            word = str(row.iloc[0])\n",
    "            pos = str(row.iloc[1])\n",
    "            chunk = str(row.iloc[2])\n",
    "            ner = str(row.iloc[3])\n",
    "            sentence.append((word, pos, chunk, ner))\n",
    "    if sentence:  \n",
    "        sentences.append(sentence)\n",
    "    return sentences\n",
    "    \n",
    "    \n",
    "def extract_data(data):\n",
    "    features = []\n",
    "    labels = []\n",
    "   \n",
    "    for sentence in data:\n",
    "        word_features = []\n",
    "        word_label = []\n",
    "        for i in range(len(sentence)):\n",
    "            word, pos, chunk, ner = sentence[i]\n",
    "            \n",
    "            feature_dict = {\n",
    "                'word': word,\n",
    "                'is_all_lower': word.lower() == word, \n",
    "                'prefix': word[:2], \n",
    "                'suffix': word[-2:], \n",
    "                'prev_word': '' if i == 0 else sentence[i - 1][0], \n",
    "                'next_word': '' if i == len(sentence) - 1 else sentence[i + 1][0], \n",
    "                'is_capitalized': word[0].upper() == word[0],\n",
    "                'is_numeric': word.isdigit(), \n",
    "                'chunk': chunk,\n",
    "                'pos': pos,\n",
    "            }\n",
    "            word_features.append(feature_dict)            \n",
    "            word_label.append(ner)\n",
    "        features.append(word_features)\n",
    "        labels.append(word_label)\n",
    "    return features, labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T08:33:19.214070Z",
     "start_time": "2024-12-01T08:33:19.208293Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "outputs": [],
   "source": [
    "train_sentences = prepare_sentences(train_df)\n",
    "val_sentences = prepare_sentences(val_df)\n",
    "test_sentences = prepare_sentences(test_df)\n",
    "\n",
    "\n",
    "train_features, train_labels = extract_data(train_sentences)\n",
    "val_features, val_labels = extract_data(val_sentences)\n",
    "test_features, test_labels = extract_data(test_sentences)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-01T08:33:26.816602Z",
     "start_time": "2024-12-01T08:33:19.602222Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a NER Classifier Model\n",
    "\n",
    "Implement one of the following classifiers for recognizing multiple entity types (e.g., person, organization, location): Conditional Random Field (CRF), biLSTM or multinomial logistic regression. Select only one and provide a brief explanation for\n",
    "your choice of model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T08:33:37.963349Z",
     "start_time": "2024-12-01T08:33:28.512625Z"
    }
   },
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs', c1=0.1, c2=0.1, max_iterations=100, all_possible_transitions=True)\n",
    "\n",
    "crf.fit(train_features, train_labels)\n",
    "label_predictions = crf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T08:33:38.546358Z",
     "start_time": "2024-12-01T08:33:38.537495Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Evaluate the model on the test set using metrics such as precision, recall, and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-01T08:33:40.093700Z",
     "start_time": "2024-12-01T08:33:39.815841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flat Accuracy Score: 0.9540047581284695\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           O     0.9878    0.9852    0.9865     38124\n",
      "       B-PER     0.8405    0.8472    0.8439      1617\n",
      "       I-PER     0.8721    0.9498    0.9093      1156\n",
      "       B-ORG     0.8065    0.7375    0.7704      1661\n",
      "       I-ORG     0.6052    0.7509    0.6702       835\n",
      "       B-LOC     0.8456    0.8046    0.8246      1668\n",
      "       I-LOC     0.7696    0.6887    0.7269       257\n",
      "      B-MISC     0.7816    0.7749    0.7783       702\n",
      "      I-MISC     0.5748    0.6759    0.6213       216\n",
      "\n",
      "   micro avg     0.9536    0.9536    0.9536     46236\n",
      "   macro avg     0.7871    0.8016    0.7924     46236\n",
      "weighted avg     0.9549    0.9536    0.9540     46236\n"
     ]
    }
   ],
   "source": [
    "print(\"Flat Accuracy Score:\", metrics.flat_accuracy_score(test_labels, label_predictions))\n",
    "  \n",
    "report = metrics.flat_classification_report(test_labels, label_predictions, labels=label_list, digits=4)\n",
    "print(\"Classification Report:\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-11-30T11:32:48.177452Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reporting\n",
    "\n",
    "Summarize your findings and suggest potential improvements for future iterations of the NER system. Additionally, discuss whether your model encountered class imbalance issues and how you addressed them. Write your suggestions to the given markdown cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initially I formatted sentences into four columns: token, POS tag, syntactic chunk tag and NER by prepare_sentences function. Then I extracted the features from formatted sentences by extract_data function. I selected nine features for each word, namely: \n",
    "    • is_all_lower: boolean representing whether the word is in lowercase or not,\n",
    "    • prefix: first two letters of the word,\n",
    "    • suffix: last two letters of the word,\n",
    "    • prev_word: previous word in the sentence (if it exists),\n",
    "    • next_word: next word in the sentence (if it exists),\n",
    "    • is_capitalized: boolean representing if the first letter is capitalized or not,\n",
    "    • is_numeric: boolean representing if the word is numeric or not,\n",
    "    • chunk: syntactic chunk tag,\n",
    "    • pos: POS tag.\n",
    "    \n",
    "After extracting features from the data, I fitted this modified data to my CRF classifier, then made a prediction with it using crf.predict function.\n",
    "\n",
    "I chose Conditional Random Field classifier for my implementation since the task was sequence labeling. CRF is advantageous over the other two classifiers because it models the dependencies between the neighbor labels. If I were to use biLSTM, each prediction for a word would be independent of the predictions of its neighbor. Logistic Regression is ill-suited to our task for the same reason: it processes words independently and predicts the label separately.\n",
    "\n",
    "This implementation of NER system made predictions with great success rates. I did not come across to any class imbalance issues. If it happened, increasing features may have helped for this problem so sacrificing computation resources might be a solution. Another solution would be using synthetic data, may be some of the minority class data can be duplicated for this reason. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Token Classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "mtl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
